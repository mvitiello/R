{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling JSON and XML\n",
    "\n",
    "Sometimes data is a TSV or nice plaintext output. Sometimes it's XML and/or JSON. This chapter walks you through what JSON and XML are, how to convert them into R-like objects, and how to extract data from them. You'll practice by examining the revision history for a Wikipedia article retrieved from the Wikipedia API using httr, xml2 and jsonlite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing JSON\n",
    "While JSON is a useful format for sharing data, your first step will often be to parse it into an R object, so you can manipulate it with R.\n",
    "\n",
    "The content() function in httr retrieves the content from a request. It takes an as argument that specifies the type of output to return. You've already seen that as = \"text\" will return the content as a character string which is useful for checking the content is as you expect.\n",
    "\n",
    "If you don't specify as, the default as = \"parsed\" is used. In this case the type of content() will be guessed based on the header and content() will choose an appropriate parsing function. For JSON this function is fromJSON() from the jsonlite package. If you know your response is JSON, you may want to use fromJSON() directly.\n",
    "\n",
    "To practice, you'll retrieve some revision history from the Wikipedia API, check it is JSON, then parse it into a list two ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do not run \n",
    "\n",
    "function (title, format = \"json\"){\n",
    "  if (title != \"Hadley Wickham\") {\n",
    "    stop('rev_history() only works for `title = \"Hadley Wickham\"`')\n",
    "  }\n",
    "  \n",
    "  if (format == \"json\"){\n",
    "    resp <- readRDS(\"had_rev_json.rds\")\n",
    "  } else if (format == \"xml\"){\n",
    "    resp <- readRDS(\"had_rev_xml.rds\")\n",
    "  } else {\n",
    "    stop('Invalid format supplied, try \"json\" or \"xml\"')\n",
    "  }\n",
    "  resp  \n",
    "}\n",
    "\n",
    "\n",
    "# Get revision history for \"Hadley Wickham\"\n",
    "resp_json <- rev_history(\"Hadley Wickham\")\n",
    "\n",
    "# Check http_type() of resp_json\n",
    "http_type(resp_json)\n",
    "\n",
    "# Examine returned text with content()\n",
    "content(resp_json, as = \"text\" )\n",
    "\n",
    "# Parse response with content()\n",
    "content(resp_json, as = \"parsed\")\n",
    "\n",
    "# Parse returned text with fromJSON()\n",
    "library(jsonlite)\n",
    "fromJSON(content(resp_json, as = \"text\" ))\n",
    "\n",
    "# the output from content() is pretty long and hard to understand. \n",
    "# Don't worry, that is just the nature of nested data, you'll learn a couple of tricks for dealing \n",
    "# with it next. However, it will be helpful to know that this response contains 5 revisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating parsed JSON\n",
    "As you saw in the video, the output from parsing JSON is a list. One way to extract relevant data from that list is to use a package specifically designed for manipulating lists, rlist.\n",
    "\n",
    "rlist provides two particularly useful functions for selecting and combining elements from a list: list.select() and list.stack(). list.select() extracts sub-elements by name from each element in a list. For example using the parsed movies data from the video (movies_list), we might ask for the title and year elements from each element:\n",
    "\n",
    "list.select(movies_list, title, year)\n",
    "\n",
    "The result is still a list, that is where list.stack() comes in. It will stack the elements of a list into a data frame.\n",
    "\n",
    "list.stack(\n",
    "    list.select(movies_list, title, year)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do not run\n",
    "\n",
    "# Load rlist\n",
    "library(rlist)\n",
    "\n",
    "# Examine output of this code\n",
    "str(content(resp_json), max.level = 4)\n",
    "\n",
    "# Store revision list\n",
    "revs <- content(resp_json)$query$pages$`41916270`$revisions\n",
    "\n",
    "# Extract the user element\n",
    "user_time <- list.select(revs, user, timestamp)\n",
    "\n",
    "# Print user_time\n",
    "print(user_time)\n",
    "\n",
    "# Stack to turn into a data frame\n",
    "list.stack(\n",
    "    list.select(revs, user, timestamp)\n",
    ")\n",
    "\n",
    "## rlist is designed to make working with lists easy, so if find you are \n",
    "# working with JSON data a lot, you should explore more of its functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting JSON\n",
    "Of course you don't have to use rlist. You can achieve the same thing by using functions from base R or the tidyverse. In this exercise you'll repeat the task of extracting the username and timestamp using the dplyr package which is part of the tidyverse.\n",
    "\n",
    "Conceptually, you'll take the list of revisions, stack them into a data frame, then pull out the relevant columns.\n",
    "\n",
    "dplyr's bind_rows() function takes a list and turns it into a data frame. Then you can use select() to extract the relevant columns. And of course if we can make use of the %>% (pipe) operator to chain them all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do not run \n",
    "\n",
    "# Load dplyr\n",
    "library(dplyr)\n",
    "\n",
    "# Pull out revision list\n",
    "revs <- content(resp_json)$query$pages$`41916270`$revisions\n",
    "\n",
    "# Extract user and timestamp\n",
    "revs %>%\n",
    "  bind_rows() %>%           \n",
    "  select(user, timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining XML documents\n",
    "Just like JSON, you should first verify the response is indeed XML with http_type() and by examining the result of content(r, as = \"text\"). Then you can turn the response into an XML document object with read_xml().\n",
    "\n",
    "One benefit of using the XML document object is the available functions that help you explore and manipulate the document. For example xml_structure() will print a representation of the XML document that emphasizes the hierarchical structure by displaying the elements without the data.\n",
    "\n",
    "In this exercise you'll grab the same revision history you've been working with as XML, and take a look at it with xml_structure()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xml2\n",
    "# install.packages(\"xml2\")\n",
    "library(xml2)\n",
    "\n",
    "# Get XML revision history\n",
    "resp_xml <- rev_history(\"Hadley Wickham\", format = \"xml\")\n",
    "\n",
    "# Check response is XML \n",
    "http_type(resp_xml)\n",
    "# Examine returned text with content()\n",
    "rev_text <- content(resp_xml, as = \"text\")\n",
    "rev_text\n",
    "\n",
    "# Turn rev_text into an XML document\n",
    "rev_xml <- read_xml(rev_text)\n",
    "\n",
    "# Examine the structure of rev_xml\n",
    "xml_structure(rev_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting XML data\n",
    "XPATHs are designed to specifying nodes in an XML document. Remember /node_name specifies nodes at the current level that have the tag node_name, where as //node_name specifies nodes at any level below the current level that have the tag node_name.\n",
    "\n",
    "xml2 provides the function xml_find_all() to extract nodes that match a given XPATH. For example, xml_find_all(rev_xml, \"/api\") will find all the nodes at the top level of the rev_xml document that have the tag api. Try running that in the console. You'll get a nodeset of one node because there is only one node that satisfies that XPATH.\n",
    "\n",
    "The object returned from xml_find_all() is a nodeset (think of it like a list of nodes). To actually get data out of the nodes in the nodeset, you'll have to explicitly ask for it with xml_text() (or xml_double() or xml_integer()).\n",
    "\n",
    "Use what you know about the location of the revisions data in the returned XML document extract just the content of the revision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do not run \n",
    "# Find all nodes using XPATH \"/api/query/pages/page/revisions/rev\"\n",
    "xml_find_all(rev_xml, \"/api/query/pages/page/revisions/rev\")\n",
    "\n",
    "# Find all rev nodes anywhere in document\n",
    "rev_nodes <- xml_find_all(rev_xml, \"//rev\")\n",
    "\n",
    "# Use xml_text() to get text from rev_nodes\n",
    "xml_text(rev_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting XML attributes\n",
    "Not all the useful data will be in the content of a node, some might also be in the attributes of a node. To extract attributes from a nodeset, xml2 provides xml_attrs() and xml_attr().\n",
    "\n",
    "xml_attrs() takes a nodeset and returns all of the attributes for every node in the nodeset. xml_attr() takes a nodeset and an additional argument attr to extract a single named argument from each node in the nodeset.\n",
    "\n",
    "In this exercise you'll grab the user and anon attributes for each revision. You'll see xml_find_first() in the sample code. It works just like xml_find_all() but it only extracts the first node it finds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT RUN\n",
    "# All rev nodes\n",
    "rev_nodes <- xml_find_all(rev_xml, \"//rev\")\n",
    "\n",
    "# The first rev node\n",
    "first_rev_node <- xml_find_first(rev_xml, \"//rev\")\n",
    "\n",
    "# Find all attributes with xml_attrs()\n",
    "xml_attrs(first_rev_node)\n",
    "\n",
    "# Find user attribute with xml_attr()\n",
    "xml_attr(first_rev_node, \"user\")\n",
    "\n",
    "# Find user attribute for all rev nodes\n",
    "xml_attr(rev_nodes, \"user\")\n",
    "\n",
    "# Find anon attribute for all rev nodes\n",
    "xml_attr(rev_nodes, \"anon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapup: returning nice API output\n",
    "How might all this work together? A useful API function will retrieve results from an API and return them in a useful form. In Chapter 2, you finished up by writing a function that retrieves data from an API that relied on content() to convert it to a useful form. To write a more robust API function you shouldn't rely on content() but instead parse the data yourself.\n",
    "\n",
    "To finish up this chapter you'll do exactly that: write get_revision_history() which retrieves the XML data for the revision history of page on Wikipedia, parses it, and returns it in a nice data frame.\n",
    "\n",
    "So that you can focus on the parts of the function that parse the return object, you'll see your function calls rev_history() to get the response from the API. You can assume this function returns the raw response and follows the best practices you learnt in Chapter 2, like using a user agent, and checking the response status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run \n",
    "\n",
    "get_revision_history <- function(article_title){\n",
    "  # Get raw revision response\n",
    "  rev_resp <- rev_history(article_title, format = \"xml\")\n",
    "  \n",
    "  # Turn the content() of rev_resp into XML\n",
    "  rev_xml <- read_xml(content(rev_resp, \"text\"))\n",
    "  \n",
    "  # Find revision nodes\n",
    "  rev_nodes <- xml_find_all(rev_xml, \"//rev\")\n",
    "\n",
    "  # Parse out usernames\n",
    "  user <- xml_attr(rev_nodes, \"user\")\n",
    "  \n",
    "  # Parse out timestamps\n",
    "  timestamp <- readr::parse_datetime(xml_attr(rev_nodes, \"timestamp\"))\n",
    "  \n",
    "  # Parse out content\n",
    "  content <- xml_text(rev_nodes)\n",
    "  \n",
    "  # Return data frame \n",
    "  data.frame(user = user,\n",
    "    timestamp = timestamp,\n",
    "    content = substr(content, 1, 40))\n",
    "}\n",
    "\n",
    "# Call function for \"Hadley Wickham\"\n",
    "get_revision_history(\"Hadley Wickham\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
